{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying Iris Species.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stzzg41_NMzf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6XVKsc7ezSH"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mglearn"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvtcChgll5oE"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()\n",
        "print(\"Keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))\n",
        "print(iris_dataset['DESCR'][:193] + \"\\n...\")\n",
        "print(\"Target names: {}\".format(iris_dataset['target_names']))\n",
        "print(\"Feature names: \\n{}\".format(iris_dataset['feature_names']))\n",
        "print(\"Type of data: {}\".format(type(iris_dataset['data'])))\n",
        "print(\"Shape of data: {}\".format(iris_dataset['data'].shape))\n",
        "print(\"First five columns of data:\\n{}\".format(iris_dataset['data'][:5]))\n",
        "print(\"Type of target: {}\".format(type(iris_dataset['target'])))\n",
        "print(\"Shape of target: {}\".format(iris_dataset['target'].shape))\n",
        "print(\"Target:\\n{}\".format(iris_dataset['target']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVpk6ZqBnCmA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
        "\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "X_train shape: (112, 4)\n",
        "y_train shape: (112,)\n",
        "\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))\n",
        "X_test shape: (38, 4)\n",
        "y_test shape: (38,)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR-xIut4oIms"
      },
      "source": [
        "# create dataframe from data in X_train\n",
        "# label the columns using the strings in iris_dataset.feature_names\n",
        "iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
        "# create a scatter matrix from the dataframe, color by y_train\n",
        "grr = pd.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',\n",
        " hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train, y_train)\n",
        "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        " metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
        " weights='uniform')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YVyiORrobdq"
      },
      "source": [
        "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
        "print(\"X_new.shape: {}\".format(X_new.shape))\n",
        "X_new.shape: (1, 4)\n",
        "\n",
        "prediction = knn.predict(X_new)\n",
        "print(\"Prediction: {}\".format(prediction))\n",
        "print(\"Predicted target name: {}\".format(\n",
        " iris_dataset['target_names'][prediction]))\n",
        "Prediction: [0]\n",
        "Predicted target name: ['setosa']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m7a4hX3ovtH"
      },
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
        "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))\n",
        "Test set score: 0.97\n",
        "print(\"Test set score: {:.2f}\".format(knn.score(X_test, y_test)))\n",
        "Test set score: 0.97"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNPZiErApA-6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train, y_train)\n",
        "print(\"Test set score: {:.2f}\".format(knn.score(X_test, y_test)))\n",
        "Test set score: 0.97"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT_pfmBjr0t0"
      },
      "source": [
        "This notebook contains a program with Python code, where a neural network is trained with Machine Learning, in this case the species of lilies that a botanist can find are classified, taking characteristics such as the lengths of their petals and sepals (width and length) these varieties of characteristics will be generated through certain libraries that will mainly take care of mathematical issues such as statistics and matrices."
      ]
    }
  ]
}